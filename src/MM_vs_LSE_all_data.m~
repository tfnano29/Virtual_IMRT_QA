% Linac 1, 2, 3, 4, 5
% use Chebyshev's solution to solve minimax problem

%% 1. load features and passing rates for Linac 1,2,3,4,5
clear all;
load('../data/data_imrt_QA');
options = optimoptions('linprog','Display','none'); % suppress linprog msg

featureValues = cell2mat(mapcheck_features(2:end,2:end));
featureNames = mapcheck_features(1,2:end);
passingValues = cell2mat(passing_rates_all(2:end,1)); % 3%/3mm

%get Linac 1,2,3,4,5 measurements
L12345 = cell2mat(mapcheck_features(2:end,73:77));
L12345 = sum(L12345,2);

id_no_linac = L12345 == 0;
featureValuesL12345 = featureValues(~id_no_linac,:);
passingValuesL12345 = passingValues(~id_no_linac,:);

%% 2. normalize data (features)
[featureValuesNorm, mu, sigdev] = zscore(featureValuesL12345,0);  %normalizes the columns
Mu_passingvalue = mean(passingValuesL12345);
passingValuesNorm = passingValuesL12345 - Mu_passingvalue;

%% 3. Minimax solution
options = optimoptions('linprog','Algorithm','interior-point-legacy','Display','iter','ConstraintTolerance', 1e-3, 'MaxIterations',1000);
[aT, x] = linprog_chebyshev(featureValuesNorm,passingValuesNorm,options);

predMM = aT * x;
diffMM = passingValuesNorm - predMM;

figure;
hist( difference ,100);
grid minor;
ylabel('Number of cases');
xlabel('Measured - Prediction');
title('Minimax Model');

%% 4. LSE solution
mdl = fitlm(featureValuesNorm,passingValuesNorm);

predLSE = predict(mdl,featureValuesNorm);
diffLse = passingValuesNorm - p;

figure;
hist(difference,100);
grid minor;
ylabel('Number of cases');
xlabel('Measured - Prediction');
title('Least-Squares Model');

figure;
plot(passingValuesNorm,passingPrediction,'ko',  'MarkerSize', 3);
hold on;
plot(1:100,1:100, 'r');
hold on;
plot(1:100, [1:100] + 3, 'r--');
hold on;
plot(1:100, [1:100] - 3, 'r--');
grid minor;
ylabel('Predicted Passing Rate');
xlabel('Actual Passing Rate');
title('Least-Square Model');
xlim([80, 100]);
ylim([80, 105]);


coefs = mdl.Coefficients.Estimate;
figure;
plot(coefs, 'ko-');
grid on;
xlabel('Feature index');
ylabel('Feature weight');
title('Least-squares');

%sort features in order of greatest weight
s = size(featureNames);
t = [1:s(2); coefs(2:end)'];
[t_sorted,ids] = sort(abs(t(2,:)), 'descend');
sortedFeatures2 = featureNames(1,ids);


x = categorical(sortedFeatures2(1:10));
x = reordercats(x,sortedFeatures2(1:10));


figure;
bar(x, t_sorted(1:10)/t_sorted(1));
grid on;
ylabel('Relative Importance');
title('Least-squares Model');

%%
featureValuesNorm = (featureValuesL12345_test - numor)./denom;%normalize(featureValuesL1_test,2);  %normalizes the columns
passingValuesNorm = passingValuesL12345_test;

ypred = predict(mdl,featureValuesNorm);

passingPrediction = ypred;
difference = passingValuesNorm - passingPrediction;

figure;
hist(difference,100);
grid minor;
ylabel('Number of occurances');
xlabel('Measured - Prediction');
title('Least-squares (test dataset)');

return
MSE_lse = immse(passingPrediction, passingValuesNorm);
MAX_lse = max(abs(difference));



coefs = mdl.Coefficients.Estimate;
figure;
plot(coefs, 'ko-');
grid on;
xlabel('Feature index');
ylabel('Feature weight');
title('Least-squares');

%sort features in order of greatest weight
s = size(featureNames);
t = [1:s(2); coefs(2:end)'];
[t_sorted,ids] = sort(abs(t(2,:)), 'descend');
sortedFeatures2 = featureNames(1,ids);
%figure; plot(passingValuesNorm, passingPrediction, 'ko'); hold on; plot([1:100],[1:100]);xlim([80 100]); ylim([80 110]); hold on; plot(passingValuesNorm, passingPrediction0, 'ro');
%}

